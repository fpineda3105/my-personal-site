---
title: 'Conoce la eficiencia de tu algoritmo usando la notaci칩n Big O'
date: '2020-09-26'
tags: 'fundamentos, Ciencias de la computaci칩n'
type: 'normal'
description: 'Como saber la eficiencia de tus algoritmos utilizando la Notaci칩n Big O'
preview: 'Si te pidiera escribir una funci칩n que calcule la sumatoria de los primeros <b>n</b> n칰meros naturales, 쯖칩mo lo har칤as?   
Tal vez lo primero que se te ocurra sea lo siguiente...'
---

Si te pidiera escribir una funci칩n que calcule la sumatoria de los primeros **n** n칰meros naturales, 쯖칩mo la har칤as?   
Tal vez lo primero que se te ocurra sea lo siguiente:

```js
function sumOf(n) {
    let totalSum = 0;
    for (let index = 1; index <= n; index++) {
        totalSum += index;
    }
    return totalSum;
}
```

Crees que hay una mejor forma de hacerlo? &#x1F914;

```js
function sumOf(n) {
    return n * (n + 1) / 2;
}
```
쮺칩mo sabemos cu치l es mejor? 쮼n base a qu칠? 쯊iempo de ejecuci칩n? 쮺antidad de recursos utilizados? 쯃egibilidad del c칩digo? Quiz치s a simple vista parece obvio, pero de manera formal podemos saberlo.


## &#10067; Notaci칩n O grande? (Big O Notation)
Es un m칠todo que se basa en las matem치ticas (&#x1F628; calma, no te asustes) para saber como se va a comportar nuestro algoritmo, calculando un apr칩ximado del n칰mero de operaciones a realizar (en el peor de los casos) dependiendo de la entrada de sus datos.
Calculemos en los ejemplos anteriores para **n** = 100

```js
// n = 100
function sumOf(n) {
    // 1 operaci칩n de asignaci칩n;
    let totalSum = 0;
    // 1 operaci칩n de asignaci칩n;
    // 1 comparaci칩n por cada iteraci칩n = 100 operaciones;
    // 1 incremento por cada iteraci칩n = 100 operaciones;
    // total = 201 operaciones;
    for (let index = 1; index <= n; index++) {
        // 1 operaci칩n de suma: totalSum + index;
        // 1 operaci칩n de asignaci칩n;
        // multiplicados por 100 iteraciones
        // total = 200 operaciones
        totalSum += index;
    }
    return totalSum;
}
```
Si sumamos todas las operaciones para **n** = 100, ser칤a un total de: **402** operaciones. Mientras **n** crece, el n칰mero de operaciones crecer치. 4 operaciones se repiten dentro del **for**. Y si lo definimos a trav칠s de una funci칩n matem치tica, el comportamiento de nuestro algoritmo ser칤a:  
f(n) = (n * 4) + 2 = 4n + 2;  

Si calculamos para el segundo algoritmo:
```js
// n = 100
function sumOf(n) {
    // 1 operaci칩n de suma; 1 operaci칩n de multiplicaci칩n; 1 operaci칩n de divisi칩n
    return n * (n + 1) / 2;
}
```
Para cualquier valor de **n** el n칰mero de operaciones siempre ser치 la misma. A trav칠s de una funci칩n matem치tica:
f(n) = 3; su comportamiento ser치 constante.

La [notaci칩n O Grande](https://es.wikipedia.org/wiki/Cota_superior_asint%C3%B3tica) se escribe *O( f(n) )* y se lee ***orden de f(n)***. Se usa para expresar la [complejidad temporal](https://es.wikipedia.org/wiki/Complejidad_temporal); tiempo que tarda un algoritmo en ejecutarse. Para el [primer ejemplo](#) que vimos, estar칤amos hablando de: *O(4n+2)* y con 4 pasos sencillos podemos definir como se comporta un algoritmo:
#### &#x1F480; Usa el peor caso 
Si quieres hacer una b칰squeda de un n칰mero dentro de un arreglo:  
```js
const numbers = [2, 8, 3, 10, 16, 30, 20, 13];

// El peor caso ser칤a el 칰ltimo elemento: number = 13;
function find(number, numbers) {
    for(let index = 0; index < numbers.length; index++) {
        if (numbers[index] === numbers) {
            return index;
        }
    }
}
```

#### &#x274C; Elimina las constantes
Para el caso que estudiamos anteriormente; *O(4n+2)* si eliminamos las constantes, nos queda: *O(n)*

#### &#x274C; Elimina los t칠rminos insignificantes
Si tuvi칠ramos un comportamiento en nuestro algoritmo *O(3n + n^2 + 3)* como *n^2* es mayor a *3n* entonces el comportamiento se reduce al mayor: *O(n^2)*

#### &#x1F38E; Toma en consideraci칩n todas las entradas
Para algoritmos donde tenemos varias entradas de datos, por ejemplo:

```js
const numbers1 = [2, 8, 3, 10, 16, 30, 20, 13];

const numbers2 = [5, 9, 7, 15, 29, 43];

function doSomething(numbers1, numbers2) {
    const n = numbers1.length;
    const m = numbers2.length;

    // O(n)
    for(let i = 0; i < n; i++) {
       // hace algo
    }

    // O(m)
    for(let j = 0; j < m; j++) {
       // hace algo
    }
}
```
Su comportamiento ser칤a ***O(n+m)***.

> Pensar치n, 춺쯊engo que pasarme la vida calculando el orden de mi algoritmo?췉,  
> pues... si y no, con el tiempo y con pr치ctica deber칤a volverse algo que al ojo lo sacas.

### &#x1F305; Funciones com칰nes de Notaci칩n O Grande
Existen algunas funciones com칰nes con las que se suele etiquetar a los algoritmos.
<div class="post-container-image">
<img src="/images/eficiencia_algoritmos/Big-O-Complexity.webp" alt="Big O Notation" title="Big O Notation" class="post-big-image">
</div>

> &#x2755; ***Nota importante:*** *Se mide el comportamiento de tu algoritmo. El tiempo que tarda un algoritmo en ejecutarse puede variar dependiendo del hardware que lo ejecute.*

#### &#x1F3C6; Orden uno *O(1)*
Si tu algoritmo es de orden 1, es lo mejor que puedes lograr, en el primer ejemplo que vimos:
```js
// n = 100
function sumOf(n) {
    // 1 operaci칩n de suma; 1 operaci칩n de multiplicaci칩n; 1 operaci칩n de divisi칩n
    return n * (n + 1) / 2;
}
```
f(n) = 3 ; dado que es una constante se etiqueta como ***O(1)***.

Otro ejemplo com칰n de orden 1 es cuando se accede a un elemento en un arreglo por su 칤ndice:
```js
const arr = [1, 2, 3, 4, 5, ...];

// O(1) no importa si es el 칰ltimo elemento del arreglo
const lastElement = arr[arr.length];
```

#### &#x1F3C6; Orden logar칤tmico *O(log n)*
Tambi칠n es de lo mejor que se puede lograr, ya que si vemos el gr치fico o recordamos un poco de nuestro paso por las matem치ticas, a medida que crece la entrada, el n칰mero de operaciones aumenta en una proporci칩n muy muy baja.

Algunos ejemplos de algoritmos con esta caracter칤stica y que veremos m치s adelante es [B칰squeda binaria](https://es.wikipedia.org/wiki/B%C3%BAsqueda_binaria).  

#### &#x1F3C5; Orden lineal *O(n)*
Es muy com칰n y f치cil de detectar, por ejemplo:
```js
// Imprimir todos los elementos de un arreglo
const arr = [1, 2, 3, 4, 5, ...];

function printAllElements(arr) {
    for (let i = 0; i < arr.length; i++) {
        console.log(arr[i]);
    }
}

printAllElements(arr);
```

#### &#x1F60C; Orden n-logar칤tmico *O(n log n)*
Lo veremos m치s adelante. Algunos de los algoritmos m치s com칰nes que son etiquetados con este orden son: [Ordenamiento por mezcla](https://es.wikipedia.org/wiki/Ordenamiento_por_mezcla) y [Divide y vencer치s](https://es.wikipedia.org/wiki/Algoritmo_divide_y_vencer%C3%A1s).


#### &#x1F9D0; Orden polin칩mico o cuadr치tico *O(n log n)* 
Son algoritmos com칰nes pero cuando te encuentras con ellos es bueno revisarlo a ver si se puede mejorar, por ejemplo:

```js
const words = [ "hello", "how" , "are", "you", "Mr.", "Jones", "how", "you", "doing" , ...];
// ciclo anidado
function hasDuplicates(words) {
    for (let i = 0; i < words.length; i++) {
        for (let j = 0; j <words.length; j++)

            if (i === j) continue;

            if (words[i] === words[j]) {
                return true;
            }
        }
    }
    return false;
}
```
Si calculamos el orden de este algoritmo ser칤a: ***O(n^2)***. Pero se puede mejorar usando un Map, veamos:
```js
const words = [ "hello", "how" , "are", "you", "Mr.", "Jones", "how", "you", "doing" , ...];

function hasDuplicates(words) {
    let dictionary = new Map();
    for (let i = 0; i < words.length; i++) {
       if (dictionary.get(words[i]) === undefined) {
           //insertamos la palabra
           dictionary.set(words[i], 1);
       } else {
           //existe la palabra, ya hay una duplicada
           return true; 
       }
    }
    return false;
}
```
En el peor de los casos, este algoritmo es de ***O(n)***.

#### &#x1F480; Orden exponencial *O(2^n)* y factorial *O(n!)*
Son casos que definitivamente se van a tardar &#x231A;, debemos ser cuidadosos. Com칰nmente hacen permutaciones de la entrada de tus datos, un ejemplo de permutaci칩n ser칤a: 

*Usando [Recursi칩n](https://es.wikipedia.org/wiki/Recursi%C3%B3n) que veremos en otro apartado.*
```js
const word = "abc";

function permute(word) {
    if (word.length < 2 ){
        return words
    }

    let permutationsArray = [];

    for (let i = 0; i < word.length; i++){
        let char = word[i];

        let remainingChars = word.slice(0, i) + word.slice(i + 1, word.length)

        for (let permutation of permute(remainingChars)) {
            permutationsArray.push(char + permutation);
        }
    }
    return permutationsArray;
}

permute(word) // [ 'abc', 'acb', 'bac', 'bca', 'cab', 'cba' ]
```

### &#x1F440; Comparaci칩n entre ***O(1)*** y ***O(n)*** 
Con el [primer ejemplo](#) que vimos, veamos un gr치fico de ambos algoritmos para los valores; **n** = 5000, 50000, 500000, 5000000, 50000000.
Usando la herramienta [Performance Tracker](https://rithmschool.github.io/function-timer-demo/) podemos ver el comportamiento de ambos algoritmos.

<div class="post-container-image">
<img src="/images/eficiencia_algoritmos/Demo_.jpg" alt="O(1) vs O(n)" title="Big O Notation" class="post-medium-image">
</div>

> *Por cierto, el primer ejemplo que vimos se trata de [N칰mero triangular](https://es.wikipedia.org/wiki/N%C3%BAmero_triangular)*

### &#x1F9E0; Complejidad espacial
Se ha hablado del n칰mero de operaciones o tiempo que toma un algoritmo para ejecutarse en base a la entrada de sus datos. Pero tambi칠n existe la [Complejidad espacial](https://es.wikipedia.org/wiki/Eficiencia_algor%C3%ADtmica#Complejidad_espacial) que debemos considerar. Se enfoca en el uso de la memoria y se representa con la misma notaci칩n. Por ejemplo, en un [caso anterior](#游븷-orden-polin칩mico-o-cuadr치tico-on-log-n) que usamos un **Map** como estructura auxiliar, estar칤amos hablando de una complejidad espacial de ***O(n)*** para que la complejidad temporal de nuestro algoritmo sea de ***O(n)***. Otro caso com칰n son los algoritmos de ordenaci칩n que usan estructuras auxiliares para reordenar los elementos.

### &#x1F4DD; Conclusiones
La eficiencia de los algoritmos que creamos es algo que siempre debemos considerar. Recuerda usar el peor caso, eliminar las constantes y los t칠rminos menos dominantes ***O(3n^2 + 10n = n^2)***. Los ciclos anidados deben re-evaluarse. Dependiendo de la cantidad de datos que estemos manuipulando nos podemos ahorrar una gran cantidad de tiempo de computo.  

Y por 칰ltimo les dejo una cita de [C. A. R. Hoare](https://es.wikipedia.org/wiki/C._A._R._Hoare):
> *춺Hay dos maneras de dise침ar software: una es hacerlo tan simple que sea obvia su falta de deficiencias, y la otra es hacerlo tan complejo que no haya deficiencias obvias췉*

### &#x1F4DA; Referencias

- [8 time complexities that every programmer should know](https://adrianmejia.com/most-popular-algorithms-time-complexity-every-programmer-should-know-free-online-tutorial-course/)
- [All you need to know about Big O Notation](https://skerritt.blog/big-o/)
- [Big O Notation Time and Space Complexity](https://skilled.dev/course/big-o-time-and-space-complexity)